{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xuj6asAxn47E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('final_data.csv')\n",
        "tok = spacy.load('en_core_web_sm')\n",
        "def tokenize (text):\n",
        "    text = str(text)\n",
        "    text_ = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
        "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
        "    nopunct = regex.sub(\" \", text.lower())\n",
        "    return [token.text for token in tok.tokenizer(nopunct)]"
      ],
      "metadata": {
        "id": "HCuYdHMdpAmE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count number of occurences of each word\n",
        "counts = Counter()\n",
        "for index, row in df.iterrows():\n",
        "    counts.update(tokenize(row['text']))"
      ],
      "metadata": {
        "id": "BcHK-aEnpF_l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#deleting infrequent words\n",
        "print(\"num_words before:\",len(counts.keys()))\n",
        "for word in list(counts):\n",
        "    if counts[word] < 2:\n",
        "        del counts[word]\n",
        "print(\"num_words after:\",len(counts.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ptQd9hKpGqO",
        "outputId": "d68ccea9-2a3a-4464-e4f0-e7732c087c8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_words before: 31225\n",
            "num_words after: 15282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating vocabulary\n",
        "vocab2index = {\"\":0, \"UNK\":1}\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in counts:\n",
        "    vocab2index[word] = len(words)\n",
        "    words.append(word)"
      ],
      "metadata": {
        "id": "RdrZ2UgppSDs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(text, vocab2index, N=70):\n",
        "    tokenized = tokenize(text)\n",
        "    encoded = np.zeros(N, dtype=int)\n",
        "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
        "    length = min(N, len(enc1))\n",
        "    encoded[:length] = enc1[:length]\n",
        "    return encoded, length"
      ],
      "metadata": {
        "id": "3UeYWIEfpTyn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['encoded'] = df['text'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "Nu9xUFE5pVUq",
        "outputId": "4594ea9a-f783-4c8a-d57b-975d471473cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  par_id      art_id    keyword country  \\\n",
              "0           0       1  @@24942188   hopeless      ph   \n",
              "1           1       2  @@21968160    migrant      gh   \n",
              "2           2       3  @@16584954  immigrant      ie   \n",
              "3           3       4   @@7811231   disabled      nz   \n",
              "4           4       5   @@1494111    refugee      ca   \n",
              "\n",
              "                                                text  label  orig_label  \\\n",
              "0  we  are living in times of absolute insanity  ...      0           0   \n",
              "1  in libya today  there are countless number of ...      0           0   \n",
              "2  white house press secretary sean spicer said t...      0           0   \n",
              "3  council customers only signs would be displaye...      0           0   \n",
              "4  just like we received migrants fleeing el salv...      0           0   \n",
              "\n",
              "                                           tokenized  \\\n",
              "0  ['living', 'times', 'absolute', 'insanity', 'p...   \n",
              "1  ['libya', 'today', 'countless', 'number', 'gha...   \n",
              "2  ['white', 'house', 'press', 'secretary', 'sean...   \n",
              "3  ['council', 'customers', 'signs', 'would', 'di...   \n",
              "4  ['like', 'received', 'migrants', 'fleeing', 'e...   \n",
              "\n",
              "                                          pos_tagged  \\\n",
              "0  [('living', 'v'), ('times', 'n'), ('absolute',...   \n",
              "1  [('libya', 'n'), ('today', 'n'), ('countless',...   \n",
              "2  [('white', 'a'), ('house', 'n'), ('press', 'n'...   \n",
              "3  [('council', 'n'), ('customers', 'n'), ('signs...   \n",
              "4  [('like', 'n'), ('received', 'v'), ('migrants'...   \n",
              "\n",
              "                                          lemmatized  \\\n",
              "0  ['live', 'time', 'absolute', 'insanity', 'pret...   \n",
              "1  ['libya', 'today', 'countless', 'number', 'gha...   \n",
              "2  ['white', 'house', 'press', 'secretary', 'sean...   \n",
              "3  ['council', 'customer', 'sign', 'would', 'disp...   \n",
              "4  ['like', 'receive', 'migrant', 'flee', 'el', '...   \n",
              "\n",
              "                                             encoded  \n",
              "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 11, 12, 13, 1...  \n",
              "1  [[6, 82, 83, 3, 84, 4, 85, 86, 8, 87, 37, 88, ...  \n",
              "2  [[107, 108, 109, 110, 111, 112, 113, 39, 28, 1...  \n",
              "3  [[127, 128, 129, 130, 117, 118, 131, 3, 91, 8,...  \n",
              "4  [[141, 142, 2, 143, 144, 145, 146, 147, 37, 14...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67b412a1-65e6-4caf-ad80-8fc0a27b5eea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>par_id</th>\n",
              "      <th>art_id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>orig_label</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tagged</th>\n",
              "      <th>lemmatized</th>\n",
              "      <th>encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>@@24942188</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>ph</td>\n",
              "      <td>we  are living in times of absolute insanity  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['living', 'times', 'absolute', 'insanity', 'p...</td>\n",
              "      <td>[('living', 'v'), ('times', 'n'), ('absolute',...</td>\n",
              "      <td>['live', 'time', 'absolute', 'insanity', 'pret...</td>\n",
              "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 11, 12, 13, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>@@21968160</td>\n",
              "      <td>migrant</td>\n",
              "      <td>gh</td>\n",
              "      <td>in libya today  there are countless number of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['libya', 'today', 'countless', 'number', 'gha...</td>\n",
              "      <td>[('libya', 'n'), ('today', 'n'), ('countless',...</td>\n",
              "      <td>['libya', 'today', 'countless', 'number', 'gha...</td>\n",
              "      <td>[[6, 82, 83, 3, 84, 4, 85, 86, 8, 87, 37, 88, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>@@16584954</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>ie</td>\n",
              "      <td>white house press secretary sean spicer said t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['white', 'house', 'press', 'secretary', 'sean...</td>\n",
              "      <td>[('white', 'a'), ('house', 'n'), ('press', 'n'...</td>\n",
              "      <td>['white', 'house', 'press', 'secretary', 'sean...</td>\n",
              "      <td>[[107, 108, 109, 110, 111, 112, 113, 39, 28, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>@@7811231</td>\n",
              "      <td>disabled</td>\n",
              "      <td>nz</td>\n",
              "      <td>council customers only signs would be displaye...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['council', 'customers', 'signs', 'would', 'di...</td>\n",
              "      <td>[('council', 'n'), ('customers', 'n'), ('signs...</td>\n",
              "      <td>['council', 'customer', 'sign', 'would', 'disp...</td>\n",
              "      <td>[[127, 128, 129, 130, 117, 118, 131, 3, 91, 8,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>@@1494111</td>\n",
              "      <td>refugee</td>\n",
              "      <td>ca</td>\n",
              "      <td>just like we received migrants fleeing el salv...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['like', 'received', 'migrants', 'fleeing', 'e...</td>\n",
              "      <td>[('like', 'n'), ('received', 'v'), ('migrants'...</td>\n",
              "      <td>['like', 'receive', 'migrant', 'flee', 'el', '...</td>\n",
              "      <td>[[141, 142, 2, 143, 144, 145, 146, 147, 37, 14...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67b412a1-65e6-4caf-ad80-8fc0a27b5eea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67b412a1-65e6-4caf-ad80-8fc0a27b5eea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67b412a1-65e6-4caf-ad80-8fc0a27b5eea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(df['orig_label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRWexqXYpXMt",
        "outputId": "5793e48d-2088-467b-ce75-a1c01c273ea9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 8529, 1: 947, 2: 144, 3: 458, 4: 391})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(df['encoded'])\n",
        "y = list(df['orig_label'])\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "D8eKIvoppZ1G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PCLDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
      ],
      "metadata": {
        "id": "rifz_vxmpbp2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = PCLDataset(X_train, y_train)\n",
        "valid_ds = PCLDataset(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "WBibWVKLpdiz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs=10, lr=0.001):\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        total = 0\n",
        "        for x, y, l in train_dl:\n",
        "            x = x.long()\n",
        "            y = y.long()\n",
        "            y_pred = model(x, l)\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.cross_entropy(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
        "        print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
        "\n",
        "def validation_metrics (model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    sum_rmse = 0.0\n",
        "    for x, y, l in valid_dl:\n",
        "        x = x.long()\n",
        "        y = y.long()\n",
        "        y_hat = model(x, l)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = torch.max(y_hat, 1)[1]\n",
        "        correct += (pred == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
        "    return sum_loss/total, correct/total, sum_rmse/total"
      ],
      "metadata": {
        "id": "hVqKqz-vpuoo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5000\n",
        "vocab_size = len(words)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "r9otpokqp75Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StackedRNN(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers) :\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim,n_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 5)\n",
        "        \n",
        "    def forward(self, x, s):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
        "        out_pack, ht = self.rnn(x_pack)\n",
        "        out = self.linear(ht[-1])\n",
        "        return out"
      ],
      "metadata": {
        "id": "0f-nRGBmp-pA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = StackedRNN(vocab_size, 200, 100,4)"
      ],
      "metadata": {
        "id": "VysnvZBnqNO3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, epochs=3, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr5nXruCqS4a",
        "outputId": "4bea141b-b612-41e5-bfe0-e84065b374c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 1.206, val loss 0.962, val accuracy 0.819, and val rmse 1.063\n",
            "train loss 0.920, val loss 0.748, val accuracy 0.819, and val rmse 1.063\n",
            "train loss 0.760, val loss 0.718, val accuracy 0.819, and val rmse 1.063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQi6Bm0TqW81"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}